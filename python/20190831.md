# O'REILLY PythonによるAI プログラミング入門

先週行ったことの復習

### 教師あり学習を用いた分類と回帰

#### 教師あり、教師なしの違い

- 教師あり
  - ラベル付き教師データを使って学習モデルを構築
- 教師なし
  - ラベル付き教師データを使わずに学習モデルを構築

#### データの前処理

データを整形して、扱いやすいようにする。

```py
input_data = np.array([
    [5.1, -2.9, 3.3],
    [-1.2, 7.8, -6.1],
    [3.9, 0.4, 2.1],
    [7.3, -9.9, -4.5]
])
```

このようなデータの集まりを、下記のような手法を使って変換する。

- 二値化
  - 数値を0か1に変換
- 平均値を引く
  - 特微ベクトルからバイアスを除去するために平均を引く。(??なんのこっちゃ)
- スケーリング
  - スケーリングして扱いやすい形にする
- 正規化
  - 特微ベクトルの尺度を合わせる
    - L1…各行において絶対値の和が1になるようにする
    - L2…各行の自乗の和が1になるようにする

#### ラベルのエンコーディング

分類する際にラベルが必要になります。
学習パッケージの`scikit-learn`は、ラベルが数字である必要があるので、ラベルのエンコーディングをして、人間とパッケージの橋渡しをします。

```py
import numpy as np
from sklearn import preprocessing

input_labels = [
    'red',
    'black',
    'red',
    'green',
    'black',
    'yellow',
    'white'   
]
encoder = preprocessing.LabelEncoder()
encoder.fit(input_labels)
print("Label mapping:")
for i, item in enumerate(encoder.classes_):
    print(item,'-->',i)
```

結果

```py
Label mapping:
black --> 0
green --> 1
red --> 2
white --> 3
yellow --> 4
```

エンコードしたものを数字に変換

```py
encoded_values = encoder.transform(test_labels)
```

逆

```py
decoded_list=encoder.inverse_transform(encoded_values)
```

#### ロジスティック回帰による分類器

入力と出力の関係の説明に使われる。

目的は、この関数を使って確率を推定することで、入力と出力の関係性を見つけ出すこと。

